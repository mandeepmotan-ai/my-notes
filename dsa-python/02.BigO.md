# Big O

- Big O is the language and metric used to describe the efficiency of algorithms
- its the way of showing how the runtime of the function increases as the size of the input increases
- it describes the upper bound of an algorithm’s growth rate
- answer to the question - “*How  does this scale as the data gets huge?*”

# The Big O Complexity Classes:

### 1. O(1) - Constant Time

- “*Golden Standard*” as execution time stays same, regardless of n = 10 items or 10 billion
- **Instant** as input size doesn’t affect performance
- no loops, just direct actions
- happens accessing a specific index in a list

### 2. O(log n) - Logarithmic Time

- “*Great Divider*” - as the input doubles, the time increases by only one small step
- the problem gets divided by half every time (eg, binary search)
- **Very Fast** as it works on Divide and Conquer strategy; halving search space
- a loop is run where the counter is multiplied or divided (e.g., `while i < n: i *= 2`)

### 3. O(n) - Linear Time

- “*Fair Play*” - time grows with direct proportion to the input size
- happens reading through a list once
- **Good/Fair** as performance scales 1:1 with input size
- a single for loop running over a list

### 4. O(n log n) - Linearithmic Time

- “*Sorter’s mark*” - it’s slightly worse than linear but still very efficient for large data
- happens in most efficient sorting algorithms (eg, merge sort, quick sort)
- **efficient for sorting** as it is best possible time for-comparison based sorting
- usually combination of dividing data (log n) and performing a linear operation (n) on each divison

### 5. O(n2) - Quadratic Time

- “*Dangerous Zone*” - if n doubles , time quadruples
- happens comparing every element in a list to every other element
- **Slow for large data** as every time is being processed against every other item
- using a for loop inside a for loop

### 6. O(2 power n) - Exponential Time

- “*Recursive Trap*” - time doubles with every single addition to the input
- happens in brute forcing recursive solutions
- Terrible speed as constant growth causes massive slow down; avoid for n>40
- a function that calls itself twice per step

### 7. O(n!) - Factorial Time

- “*Nightmare*” - Even with just 20-30 times, the program might take years to finish
- happens while calculating every possible permutation
- **Broken** as it’s impossible to compute for even moderately sized inputs

# The 4 Golden Rules of Big O Analysis:

### 1. The Worst-Case Rule

- when Big O is used, it means we almost always talk about *the worst case scenario*
- in short we are assuming *the highest possible maximum steps the function would take* and according to that we are calculating Big O
- we always assume the worst case scenario (O(n)) to be safe

### 2. Drop the Constants

- we don’t care about the exact number of operations, we just care about the trend
- we only care about the fast-growing term, so we ignore constants
- eg,
    - O(2n² + 100) → O(n²)
    - O(n log n + n) → O(n log n)

### 3. Drop Non-Dominant Terms

- we drop non-dominant terms in function working like $O(n^2)$ and other part is O(n) , we will simply ignore O(n) as it becomes irrelevant as n gets very big
- $O(n^2 + n) simplifies O(n^2).$

### 4. Add vs Mutliply

- when there are two separate loops running, such that one loop runs and then another loop runs after first loop, then we add
    - Two separate loops → O(a + b)
- when there is a loop inside loop (nested loop), we multiply
    - a loop inside a loop → O(a*b)

# The Cases

### 1. The Worst Case Scenario (O - Big (O))

- **upper bound,** the absolute *maximum time the algorithm could take*
- max steps possible by function
- useful in scenarios such as searching for item that is last in the list

### 2. Big Omega  ($\Omega$) - Best Case

- **lower bound,** the absolute *minimum time required*
- minimum steps possible
- useful in scenarios such as searching for item that is first in the list

### 3. Big Theta ( $\Theta$ ) - Average Case

- **tight bound,** the *behavior of algorithm on typical, random data*
- expected steps for some random input
- useful for scenarios such as finding the name somewhere in the middle of the list